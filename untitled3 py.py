# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RP6OE6JX-NSGphps3OP6lqX9X7gu1oSO
"""

!nvidia-smi
!pip install -q transformers accelerate torch sentencepiece

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

model_id = "Qwen/Qwen2.5-7B-Instruct"

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    device_map="auto"
)

def chat(system, user):
    prompt = f"""<|system|>
{system}
<|user|>
{user}
<|assistant|>
"""
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_new_tokens=200,
            temperature=0.7
        )

    print(tokenizer.decode(output[0], skip_special_tokens=True))

chat(
    system="You are a professional business assistant helping a startup founder.",
    user="Give me 3 AI startup ideas for 2026."
)

chat(
    system="You are in roleplay mode. Act as a medieval knight.",
    user="Describe your mission."
)

chat(
    system="You are a senior software engineer. Give clean, correct code.",
    user="Write a Python function to check if a number is prime."
)

def set_mode(mode):
    if mode == "business":
        return "You are a professional business assistant helping a startup founder."
    elif mode == "coding":
        return "You are a senior software engineer. Give clean, correct code."
    elif mode == "roleplay":
        return "You are in roleplay mode. Act as a medieval knight."
    else:
        return "You are a helpful AI assistant."

# Example:
chat(set_mode("coding"), "Write a Python program to reverse a string.")

chat(set_mode("business"), "Give me marketing strategies for a new AI tool.")
chat(set_mode("coding"), "Write a Python script to sort a list of numbers.")
chat(set_mode("roleplay"), "Tell a story as a pirate.")

!pip install -q gradio

import gradio as gr

def ai_interface(user_input, mode):
    # Choose system prompt based on mode
    if mode == "Business":
        system_prompt = "You are a professional business assistant helping a startup founder."
    elif mode == "Coding":
        system_prompt = "You are a senior software engineer. Give clean, correct code."
    elif mode == "Roleplay":
        system_prompt = "You are in roleplay mode. Act as a medieval knight."
    else:
        system_prompt = "You are a helpful AI assistant."

    # Get AI response
    prompt_response = chat(system_prompt, user_input)
    return prompt_response

# Create Gradio interface
iface = gr.Interface(
    fn=ai_interface,
    inputs=[gr.Textbox(lines=2, placeholder="Enter your message here..."),
            gr.Dropdown(["Business", "Coding", "Roleplay"], value="Business")],
    outputs="text",
    title="My AI Assistant",
    description="Chat with your AI in different modes!"
)

iface.launch()

chat(
    system="You are a helpful AI assistant.",
    user="Say hello."
)

def chat_return(system, user):
    prompt = f"""<|system|>
{system}
<|user|>
{user}
<|assistant|>
"""
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_new_tokens=150,
            temperature=0.7
        )

    return tokenizer.decode(output[0], skip_special_tokens=True)

import gradio as gr

def ai_interface(user_input, mode):
    if mode == "Business":
        system_prompt = "You are a professional business assistant helping a startup founder."
    elif mode == "Coding":
        system_prompt = "You are a senior software engineer. Give clean, correct code."
    elif mode == "Roleplay":
        system_prompt = "You are in roleplay mode. Act as a medieval knight."
    else:
        system_prompt = "You are a helpful AI assistant."

    # Use the updated chat_return function
    response = chat_return(system_prompt, user_input)
    return response

iface = gr.Interface(
    fn=ai_interface,
    inputs=[gr.Textbox(lines=2, placeholder="Enter your message here..."),
            gr.Dropdown(["Business", "Coding", "Roleplay"], value="Business")],
    outputs="text",
    title="My AI Assistant",
    description="Chat with your AI in different modes!"
)

iface.launch()

!pip freeze > requirements.txt

!zip -r my_ai.zip /content

from google.colab import files
files.download('requirements.txt')

from google.colab import files
files.download('my_ai.zip')